{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64c51ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 1997\n",
      "Successfully read 1998\n",
      "Successfully read 1999\n",
      "Successfully read 2000\n",
      "Successfully read 2001\n",
      "Successfully read 2002\n",
      "Successfully read 2003\n",
      "Successfully read 2004\n",
      "Successfully read 2005\n",
      "Successfully read 2006\n",
      "Successfully read 2007\n",
      "Successfully read 2008\n",
      "Successfully read 2009\n",
      "Successfully read 2010\n",
      "Successfully read 2011\n",
      "Successfully read 2012\n",
      "Successfully read 2013\n",
      "Successfully read 2014\n",
      "Successfully read 2015\n",
      "Successfully read 2016\n",
      "Successfully read 2017\n",
      "Successfully read 2018\n",
      "Successfully read 2019\n",
      "Successfully read 2020\n",
      "Successfully read 2021\n",
      "Successfully read 2022\n",
      "Successfully read 2023\n",
      "Successfully read 2024\n",
      "Successfully read 2025\n",
      "Successfully merged 29 files\n",
      "Merged data saved to 'merged_birthPlaceRegion_sex.csv'\n"
     ]
    }
   ],
   "source": [
    "# Merge data of CSV files we are going to use\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "from os import makedirs\n",
    "\n",
    "# Define data path\n",
    "dataPath = '../data/birthPlaceRegion/'\n",
    "mergedPath = '../data/merged_data/'\n",
    "if not exists(mergedPath):\n",
    "    makedirs(mergedPath)\n",
    "\n",
    "\n",
    "# Define file paths for each year\n",
    "def merge_csvs_explicit():\n",
    "    years = range(1997, 2026)  # Only up to 2024 (existing data)\n",
    "    \n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        file_path = f\"{dataPath}{year}_birthPlaceRegion_sex.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=',')\n",
    "            # Replace '..' with 0 in column 'Value' and coerce to numeric\n",
    "            if 'Value' in df.columns:\n",
    "                df['Value'] = df['Value'].replace('..', 0)\n",
    "                df['Value'] = pd.to_numeric(df['Value'], errors='coerce').fillna(0)\n",
    "            dfs.append(df)\n",
    "            print(f\"Successfully read {year}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File for year {year} not found\")\n",
    "    \n",
    "    if dfs:\n",
    "        df_all_years = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"Successfully merged {len(dfs)} files\")\n",
    "        return df_all_years\n",
    "    else:\n",
    "        print(\"No files were found to merge\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df_combined = merge_csvs_explicit()  # or merge_csvs_explicit()\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df_combined.to_csv(f\"{mergedPath}merged_birthPlaceRegion_sex.csv\", index=False)\n",
    "print(\"Merged data saved to 'merged_birthPlaceRegion_sex.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "312c0ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 1997\n",
      "Successfully read 1998\n",
      "Successfully read 1999\n",
      "Successfully read 2000\n",
      "Successfully read 2001\n",
      "Successfully read 2002\n",
      "Successfully read 2003\n",
      "Successfully read 2004\n",
      "Successfully read 2005\n",
      "Successfully read 2006\n",
      "Successfully read 2007\n",
      "Successfully read 2008\n",
      "Successfully read 2009\n",
      "Successfully read 2010\n",
      "Successfully read 2011\n",
      "Successfully read 2012\n",
      "Successfully read 2013\n",
      "Successfully read 2014\n",
      "Successfully read 2015\n",
      "Successfully read 2016\n",
      "Successfully read 2017\n",
      "Successfully read 2018\n",
      "Successfully read 2019\n",
      "Successfully read 2020\n",
      "Successfully read 2021\n",
      "Successfully read 2022\n",
      "Successfully read 2023\n",
      "Successfully read 2024\n",
      "Successfully read 2025\n",
      "Successfully merged 29 files\n",
      "Merged data saved to 'merged_birthPlace_spain_v_outside.csv'\n"
     ]
    }
   ],
   "source": [
    "# Merge data of CSV files Data_Lloc_naix_(esp_vs_fuera)\n",
    "#Define data path\n",
    "dataPath = '../data/birthPlace_spain_v_outside/'\n",
    "mergedPath = '../data/merged_data/'\n",
    "# Define file paths for each year\n",
    "def merge_csvs_explicit_esp():\n",
    "    years = range(1997, 2026)  # Only up to 2024 (existing data)\n",
    "    \n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        file_path = f\"{dataPath}{year}_birthPlace_spain_v_outside.csv\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=',')\n",
    "            # Replace '..' with 0 in column 'Value' and coerce to numeric\n",
    "            if 'Value' in df.columns:\n",
    "                df['Value'] = df['Value'].replace('..', 0)\n",
    "                df['Value'] = pd.to_numeric(df['Value'], errors='coerce').fillna(0)\n",
    "            dfs.append(df)\n",
    "            print(f\"Successfully read {year}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File for year {year} not found\")\n",
    "    \n",
    "    if dfs:\n",
    "        df_all_years = pd.concat(dfs, ignore_index=True)\n",
    "        print(f\"Successfully merged {len(dfs)} files\")\n",
    "        return df_all_years\n",
    "    else:\n",
    "        print(\"No files were found to merge\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df_combined = merge_csvs_explicit_esp()  # or merge_csvs_explicit()\n",
    "# Save the combined DataFrame to a new CSV file\n",
    "df_combined.to_csv(f\"{mergedPath}merged_birthPlace_spain_v_outside.csv\", index=False)\n",
    "print(\"Merged data saved to 'merged_birthPlace_spain_v_outside.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5014b6",
   "metadata": {},
   "source": [
    "## Data Adoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "059eca35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed t15833202300-201200.csv\n",
      "Processed t15833201100.csv\n",
      "Processed t15833201000.csv\n",
      "Processed t15833200900.csv\n",
      "Processed t15833200800-199800.csv\n",
      "Saved merged_adoption_total.csv with 1678 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Value",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "3ac85c4e-e9ab-4f22-aa64-06fd14ef326b",
       "rows": [
        [
         "0",
         "Niños adoptados",
         "2023",
         "64"
        ],
        [
         "1",
         "Total Europa",
         "2023",
         "1"
        ],
        [
         "2",
         "Bosnia y Herzegovina",
         "2023",
         "0"
        ],
        [
         "3",
         "Bulgaria",
         "2023",
         "0"
        ],
        [
         "4",
         "Croacia",
         "2023",
         "0"
        ],
        [
         "5",
         "Georgia",
         "2023",
         "0"
        ],
        [
         "6",
         "Hungria",
         "2023",
         "0"
        ],
        [
         "7",
         "Lituania",
         "2023",
         "0"
        ],
        [
         "8",
         "República Checa",
         "2023",
         "0"
        ],
        [
         "9",
         "Rumania",
         "2023",
         "0"
        ],
        [
         "10",
         "Moldavia",
         "2023",
         "0"
        ],
        [
         "11",
         "Polonia",
         "2023",
         "0"
        ],
        [
         "12",
         "Rusia",
         "2023",
         "0"
        ],
        [
         "13",
         "Ucrania",
         "2023",
         "0"
        ],
        [
         "14",
         "Resto de Europa",
         "2023",
         "1"
        ],
        [
         "15",
         "Total África",
         "2023",
         "10"
        ],
        [
         "16",
         "Burkina Faso",
         "2023",
         "0"
        ],
        [
         "17",
         "Congo",
         "2023",
         "0"
        ],
        [
         "18",
         "Camerún",
         "2023",
         "0"
        ],
        [
         "19",
         "Costa de Marfil",
         "2023",
         "5"
        ],
        [
         "20",
         "Gambia",
         "2023",
         "0"
        ],
        [
         "21",
         "Ghana",
         "2023",
         "0"
        ],
        [
         "22",
         "Guinea Bissau",
         "2023",
         "0"
        ],
        [
         "23",
         "Etiopia",
         "2023",
         "0"
        ],
        [
         "24",
         "Mali",
         "2023",
         "0"
        ],
        [
         "25",
         "Madagascar",
         "2023",
         "4"
        ],
        [
         "26",
         "Marruecos",
         "2023",
         "0"
        ],
        [
         "27",
         "Nigeria",
         "2023",
         "0"
        ],
        [
         "28",
         "República Democrática del Congo",
         "2023",
         "0"
        ],
        [
         "29",
         "Sierra Leona",
         "2023",
         "0"
        ],
        [
         "30",
         "Senegal",
         "2023",
         "0"
        ],
        [
         "31",
         "Togo",
         "2023",
         "0"
        ],
        [
         "32",
         "Resto de África",
         "2023",
         "1"
        ],
        [
         "33",
         "Total América",
         "2023",
         "26"
        ],
        [
         "34",
         "Bolivia",
         "2023",
         "7"
        ],
        [
         "35",
         "Brasil",
         "2023",
         "0"
        ],
        [
         "36",
         "Colombia",
         "2023",
         "5"
        ],
        [
         "37",
         "Costa Rica",
         "2023",
         "0"
        ],
        [
         "38",
         "El Salvador",
         "2023",
         "0"
        ],
        [
         "39",
         "Ecuador",
         "2023",
         "0"
        ],
        [
         "40",
         "Guatemala",
         "2023",
         "0"
        ],
        [
         "41",
         "Haití",
         "2023",
         "5"
        ],
        [
         "42",
         "Honduras",
         "2023",
         "1"
        ],
        [
         "43",
         "México",
         "2023",
         "0"
        ],
        [
         "44",
         "Nicaragua",
         "2023",
         "0"
        ],
        [
         "45",
         "Panamá",
         "2023",
         "0"
        ],
        [
         "46",
         "Perú",
         "2023",
         "4"
        ],
        [
         "47",
         "República Dominicana",
         "2023",
         "4"
        ],
        [
         "48",
         "Venezuela",
         "2023",
         "0"
        ],
        [
         "49",
         "Chile",
         "2023",
         "0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1678
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Niños adoptados</td>\n",
       "      <td>2023</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Europa</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bosnia y Herzegovina</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Croacia</td>\n",
       "      <td>2023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>Tailandia</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>China</td>\n",
       "      <td>1998</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>Resto de Asia</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>Total Oceania</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1678 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Category  Year  Value\n",
       "0          Niños adoptados  2023     64\n",
       "1             Total Europa  2023      1\n",
       "2     Bosnia y Herzegovina  2023      0\n",
       "3                 Bulgaria  2023      0\n",
       "4                  Croacia  2023      0\n",
       "...                    ...   ...    ...\n",
       "1673             Tailandia  1998      0\n",
       "1674               Vietnam  1998      0\n",
       "1675                 China  1998     28\n",
       "1676         Resto de Asia  1998      0\n",
       "1677         Total Oceania  1998      0\n",
       "\n",
       "[1678 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to adoption folders\n",
    "from ntpath import join\n",
    "from os.path import exists\n",
    "from os import makedirs\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "path_adoption_tot = '../data_original/adoption/Total_adoption/'\n",
    "path_adoption_inq = '../data_original/adoption/Adoption_inquiries/'\n",
    "mergedPath = '../data/merged_data/'\n",
    "if not exists(mergedPath):\n",
    "    makedirs(mergedPath)\n",
    "# Merge adoption total data\n",
    "# ...existing code...\n",
    "def merge_adoption_data(path, out_name='merged_adoption_total.csv'):\n",
    "    import re\n",
    "    from io import StringIO\n",
    "    from os.path import join\n",
    "\n",
    "    files = [\n",
    "        't15833202300-201200.csv',\n",
    "        't15833201100.csv',\n",
    "        't15833201000.csv',\n",
    "        't15833200900.csv',\n",
    "        't15833200800-199800.csv'\n",
    "    ]\n",
    "\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        fp = join(path, file)\n",
    "        try:\n",
    "            with open(fp, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: {file} not found in {path}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # find the header line that starts with a comma followed by a 4-digit year (handles single- and multi-year files)\n",
    "        header_idx = None\n",
    "        for i, line in enumerate(lines):\n",
    "            if re.match(r'^\\s*,\\s*\\d{4}', line):\n",
    "                header_idx = i\n",
    "                break\n",
    "        # fallback: any line that contains a 4-digit year\n",
    "        if header_idx is None:\n",
    "            for i, line in enumerate(lines):\n",
    "                if re.search(r'\\d{4}', line):\n",
    "                    header_idx = i\n",
    "                    break\n",
    "        if header_idx is None:\n",
    "            print(f\"Warning: year-header row not found in {file}, skipping\")\n",
    "            continue\n",
    "\n",
    "        csv_text = ''.join(lines[header_idx:])  # header + data portion\n",
    "        try:\n",
    "            tmp = pd.read_csv(StringIO(csv_text), sep=',', header=0, dtype=str, keep_default_na=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV portion of {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Ensure a column name for the first column and forward-fill broken rows\n",
    "        first_col = tmp.columns[0]\n",
    "        if first_col == '' or first_col is None:\n",
    "            tmp = tmp.rename(columns={tmp.columns[0]: 'Category'})\n",
    "            first_col = 'Category'\n",
    "        tmp[first_col] = tmp[first_col].replace('', pd.NA).ffill()\n",
    "\n",
    "        # melt to long format: Category | Year | Value\n",
    "        long = tmp.melt(id_vars=[first_col], var_name='Year', value_name='Value')\n",
    "\n",
    "        # cleanup Year and Value\n",
    "        long['Year'] = long['Year'].astype(str).str.extract(r'(\\d{4})')[0]\n",
    "        long = long.dropna(subset=['Year'])\n",
    "        long['Year'] = long['Year'].astype(int)\n",
    "\n",
    "        long['Value'] = long['Value'].astype(str).str.strip()\n",
    "        long['Value'] = long['Value'].replace({'': None, '..': None})\n",
    "        long['Value'] = pd.to_numeric(long['Value'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "        long = long.rename(columns={first_col: 'Category'})\n",
    "\n",
    "        dfs.append(long)\n",
    "        print(f\"Processed {file}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(\"No adoption files merged\")\n",
    "        return None\n",
    "\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    if not exists(mergedPath):\n",
    "        makedirs(mergedPath)\n",
    "    df_all.to_csv(join(mergedPath, out_name), index=False)\n",
    "    print(f\"Saved {out_name} with {len(df_all)} rows\")\n",
    "    return df_all\n",
    "# ...existing code...\n",
    "\n",
    "# Merge adoption total data\n",
    "merge_adoption_data(path_adoption_tot, out_name='merged_adoption_total.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce2222",
   "metadata": {},
   "source": [
    "#### Data Clean for Adoption Inquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01b7ecd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strip_header_and_save() missing 1 required positional argument: 'out_fp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaved cleaned CSV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_fp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Example: clean one file\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mstrip_header_and_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data_original/adoption/Adoption_inquiries/t15832c1.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Batch: process all CSVs in a folder\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: strip_header_and_save() missing 1 required positional argument: 'out_fp'"
     ]
    }
   ],
   "source": [
    "# Clean adoption inquiries data files by stripping extraneous headers\n",
    "def strip_header_and_save(in_fp, out_fp):\n",
    "    import re\n",
    "    from io import StringIO\n",
    "    import pandas as pd\n",
    "\n",
    "    with open(in_fp, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Prefer header lines like \",2009\" or \",2023,2022,...\"\n",
    "    header_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if re.match(r'^\\s*,\\s*\\d{4}', line):\n",
    "            header_idx = i\n",
    "            break\n",
    "\n",
    "    # fallback: find first data-like line (contains digits and commas) and take previous line as header\n",
    "    if header_idx is None:\n",
    "        for i, line in enumerate(lines):\n",
    "            if ',' in line and re.search(r'\\d', line):\n",
    "                header_idx = max(0, i - 1)\n",
    "                break\n",
    "\n",
    "    if header_idx is None:\n",
    "        raise RuntimeError(f\"Header not found in {in_fp}\")\n",
    "\n",
    "    csv_text = ''.join(lines[header_idx:])\n",
    "    df = pd.read_csv(StringIO(csv_text), sep=',', header=0, dtype=str, keep_default_na=False)\n",
    "    df.to_csv(out_fp, index=False)\n",
    "    print(f\"Saved cleaned CSV: {out_fp}\")\n",
    "\n",
    "# Example: clean one file\n",
    "strip_header_and_save(\n",
    "    \"../data_original/adoption/Adoption_inquiries/t15832c1.csv\")\n",
    "# Batch: process all CSVs in a folder\n",
    "import os, glob\n",
    "folder = \"../data_original/adoption/Adoption_inquiries/\"\n",
    "for fp in glob.glob(os.path.join(folder, \"*.csv\")):\n",
    "    out = fp.replace(\".csv\", \"_clean.csv\")\n",
    "    try:\n",
    "        strip_header_and_save(fp, out)\n",
    "    except Exception as e:\n",
    "        print(\"Skipped\", fp, \"->\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
